{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "sys.path.append('../scripts/')\n",
    "from get_csv_from_metadata import make_csv_from_metadata\n",
    "from IPython.display import Video\n",
    "sys.path.append('../scripts/helper_functions_cv/tensorflow_helpers/')\n",
    "from gpu_starter_mirror_strategy import start_gpus\n",
    "import cv2, PIL\n",
    "from PIL import Image\n",
    "import multiprocessing as mp\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from save_weights_every_epoch import CallbackForSavingModelWeights\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videos = glob.glob('../../ml-data-training/deep_fake_data/comp_data/train_sample_videos/*.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = make_csv_from_metadata('../../ml-data-training/deep_fake_data/comp_data/train_sample_videos/metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['updated_file_name'] = csv['file_name'].apply(lambda x: '../../ml-data-training/deep_fake_data/comp_data/train_sample_videos/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_binary_labels(label):\n",
    "    if label == 'FAKE':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['binary_labels'] = csv['labels'].apply(apply_binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "Returning objects as strategy, replicas and auto in same order.\n"
     ]
    }
   ],
   "source": [
    "strategy, REPLICAS, AUTO = start_gpus([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video(csv['updated_file_name'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = csv['updated_file_name'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(path):\n",
    "    try:\n",
    "        folder_name = path.split('/')[-1].split('.')[0]\n",
    "        folder_path = f'../../imgs_files/{folder_name}/'\n",
    "        os.makedirs(folder_path)\n",
    "        vidcap = cv2.VideoCapture(path)\n",
    "        success, image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            cv2.imwrite(f'{folder_path}{count}.jpg', image)\n",
    "            success, image = vidcap.read()\n",
    "            count += 1\n",
    "        return 'DONE'\n",
    "    except:\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(25) as p:\n",
    "    results = p.map(save_imgs, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = glob.glob('../../imgs_files/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = csv[['file_name', 'labels']].values.tolist()\n",
    "file_labels = [[x[0].split('.')[0], x[1]] for x in file_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = dict(zip([x[0] for x in file_labels], [1 if x[1] == 'FAKE' else 0 for x in file_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for x in img_files:\n",
    "    labels.append(label_dict[x.split('/')[-2]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tuples = [(img_files[x], labels[x]) for x in range(len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(generator_, test_size = 0.01):\n",
    "    train, test = train_test_split(generator_, test_size = 0.01, random_state=42)\n",
    "    train, val = train_test_split(train, test_size=0.01, random_state=42)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(final_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_imgs(img, label):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    img = img / 255\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, shape = (256, 256), repeat = True, shuffle = True, batch = True, prefetch = True, batch_size = 64):\n",
    "    imgs = [x[0] for x in data]\n",
    "    labels = [x[1] for x in data]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "    tensor = tensor.cache()\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if shuffle:\n",
    "        tensor = tensor.shuffle(1024 * REPLICAS)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        tensor = tensor.with_options(opt)\n",
    "    tensor = tensor.map(read_train_imgs, num_parallel_calls = AUTO)\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    if prefetch:\n",
    "        tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, shape):\n",
    "    with strategy.scope():\n",
    "        input_layer = tf.keras.Input(shape = shape)\n",
    "        construct = getattr(keras.applications, model_name)\n",
    "        mid_layer = construct(include_top = False, \n",
    "            weights = None, \n",
    "            pooling = 'avg')(input_layer)\n",
    "        last_layer = keras.layers.Dense(1, activation = 'sigmoid')(mid_layer)\n",
    "        model = keras.Model(input_layer, last_layer)\n",
    "    return model\n",
    "def compile_new_model(model):\n",
    "    with strategy.scope():\n",
    "        loss = keras.losses.BinaryCrossentropy()\n",
    "        optimizer = keras.optimizers.SGD()\n",
    "        prec = keras.metrics.Precision(name = 'prec')\n",
    "        rec = keras.metrics.Recall(name = 'rec')\n",
    "        model.compile(\n",
    "            loss = loss,\n",
    "            optimizer = optimizer,\n",
    "            metrics = [prec, rec]\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(train)\n",
    "val_dataset = get_data(val, repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "306/306 [==============================] - 74s 143ms/step - loss: 0.4933 - prec: 0.8221 - rec: 0.9682 - val_loss: 0.5258 - val_prec: 0.8056 - val_rec: 1.0000\n",
      "Epoch 2/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.3904 - prec: 0.8483 - rec: 0.9566 - val_loss: 0.4214 - val_prec: 0.8143 - val_rec: 0.9854\n",
      "Epoch 3/50\n",
      "306/306 [==============================] - 40s 129ms/step - loss: 0.3485 - prec: 0.8649 - rec: 0.9521 - val_loss: 0.4413 - val_prec: 0.9200 - val_rec: 0.7931\n",
      "Epoch 4/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.3147 - prec: 0.8794 - rec: 0.9497 - val_loss: 0.3294 - val_prec: 0.8894 - val_rec: 0.9331\n",
      "Epoch 5/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.2884 - prec: 0.8904 - rec: 0.9482 - val_loss: 0.3120 - val_prec: 0.9184 - val_rec: 0.8934\n",
      "Epoch 6/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.2673 - prec: 0.8994 - rec: 0.9472 - val_loss: 0.2944 - val_prec: 0.8766 - val_rec: 0.9728\n",
      "Epoch 7/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.2499 - prec: 0.9074 - rec: 0.9470 - val_loss: 0.2655 - val_prec: 0.9026 - val_rec: 0.9488\n",
      "Epoch 8/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.2314 - prec: 0.9158 - rec: 0.9477 - val_loss: 0.2453 - val_prec: 0.8962 - val_rec: 0.9655\n",
      "Epoch 9/50\n",
      "306/306 [==============================] - 40s 129ms/step - loss: 0.2151 - prec: 0.9230 - rec: 0.9497 - val_loss: 0.2203 - val_prec: 0.9112 - val_rec: 0.9645\n",
      "Epoch 10/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.1986 - prec: 0.9295 - rec: 0.9506 - val_loss: 0.2325 - val_prec: 0.9201 - val_rec: 0.9624\n",
      "Epoch 11/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.1862 - prec: 0.9353 - rec: 0.9522 - val_loss: 0.1982 - val_prec: 0.9295 - val_rec: 0.9509\n",
      "Epoch 12/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.1754 - prec: 0.9400 - rec: 0.9542 - val_loss: 0.2015 - val_prec: 0.9299 - val_rec: 0.9697\n",
      "Epoch 13/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1656 - prec: 0.9435 - rec: 0.9555 - val_loss: 0.1668 - val_prec: 0.9378 - val_rec: 0.9603\n",
      "Epoch 14/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1560 - prec: 0.9468 - rec: 0.9574 - val_loss: 0.1617 - val_prec: 0.9556 - val_rec: 0.9457\n",
      "Epoch 15/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1467 - prec: 0.9510 - rec: 0.9590 - val_loss: 0.1510 - val_prec: 0.9486 - val_rec: 0.9645\n",
      "Epoch 16/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1406 - prec: 0.9523 - rec: 0.9599 - val_loss: 0.1692 - val_prec: 0.9496 - val_rec: 0.9446\n",
      "Epoch 17/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1346 - prec: 0.9547 - rec: 0.9611 - val_loss: 0.1344 - val_prec: 0.9599 - val_rec: 0.9498\n",
      "Epoch 18/50\n",
      "306/306 [==============================] - 39s 127ms/step - loss: 0.1279 - prec: 0.9577 - rec: 0.9631 - val_loss: 0.1584 - val_prec: 0.9455 - val_rec: 0.9425\n",
      "Epoch 19/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1219 - prec: 0.9598 - rec: 0.9642 - val_loss: 0.1747 - val_prec: 0.9224 - val_rec: 0.9812\n",
      "Epoch 20/50\n",
      "306/306 [==============================] - 40s 129ms/step - loss: 0.1168 - prec: 0.9615 - rec: 0.9655 - val_loss: 0.1234 - val_prec: 0.9489 - val_rec: 0.9707\n",
      "Epoch 21/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1119 - prec: 0.9628 - rec: 0.9661 - val_loss: 0.1299 - val_prec: 0.9563 - val_rec: 0.9613\n",
      "Epoch 22/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.1084 - prec: 0.9643 - rec: 0.9677 - val_loss: 0.1318 - val_prec: 0.9633 - val_rec: 0.9603\n",
      "Epoch 23/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.1068 - prec: 0.9651 - rec: 0.9680 - val_loss: 0.1110 - val_prec: 0.9485 - val_rec: 0.9812\n",
      "Epoch 24/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.0992 - prec: 0.9672 - rec: 0.9699 - val_loss: 0.1134 - val_prec: 0.9536 - val_rec: 0.9666\n",
      "Epoch 25/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0974 - prec: 0.9676 - rec: 0.9702 - val_loss: 0.1901 - val_prec: 0.9676 - val_rec: 0.9363\n",
      "Epoch 26/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0958 - prec: 0.9689 - rec: 0.9714 - val_loss: 0.1031 - val_prec: 0.9675 - val_rec: 0.9655\n",
      "Epoch 27/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0915 - prec: 0.9698 - rec: 0.9717 - val_loss: 0.1156 - val_prec: 0.9746 - val_rec: 0.9634\n",
      "Epoch 28/50\n",
      "306/306 [==============================] - 39s 127ms/step - loss: 0.0906 - prec: 0.9705 - rec: 0.9722 - val_loss: 0.1234 - val_prec: 0.9416 - val_rec: 0.9781\n",
      "Epoch 29/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0869 - prec: 0.9714 - rec: 0.9731 - val_loss: 0.0972 - val_prec: 0.9542 - val_rec: 0.9801\n",
      "Epoch 30/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0874 - prec: 0.9718 - rec: 0.9731 - val_loss: 0.1127 - val_prec: 0.9511 - val_rec: 0.9749\n",
      "Epoch 31/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0803 - prec: 0.9741 - rec: 0.9746 - val_loss: 0.1092 - val_prec: 0.9572 - val_rec: 0.9822\n",
      "Epoch 32/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.0802 - prec: 0.9741 - rec: 0.9754 - val_loss: 0.0977 - val_prec: 0.9608 - val_rec: 0.9739\n",
      "Epoch 33/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.0787 - prec: 0.9747 - rec: 0.9758 - val_loss: 0.1143 - val_prec: 0.9571 - val_rec: 0.9791\n",
      "Epoch 34/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0784 - prec: 0.9750 - rec: 0.9766 - val_loss: 0.1131 - val_prec: 0.9551 - val_rec: 0.9781\n",
      "Epoch 35/50\n",
      "306/306 [==============================] - 39s 127ms/step - loss: 0.0766 - prec: 0.9760 - rec: 0.9765 - val_loss: 0.0904 - val_prec: 0.9561 - val_rec: 0.9791\n",
      "Epoch 36/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0739 - prec: 0.9758 - rec: 0.9769 - val_loss: 0.0978 - val_prec: 0.9678 - val_rec: 0.9739\n",
      "Epoch 37/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0722 - prec: 0.9769 - rec: 0.9780 - val_loss: 0.0834 - val_prec: 0.9650 - val_rec: 0.9801\n",
      "Epoch 38/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0708 - prec: 0.9776 - rec: 0.9782 - val_loss: 0.1118 - val_prec: 0.9677 - val_rec: 0.9718\n",
      "Epoch 39/50\n",
      "306/306 [==============================] - 39s 127ms/step - loss: 0.0696 - prec: 0.9780 - rec: 0.9783 - val_loss: 0.1388 - val_prec: 0.9504 - val_rec: 0.9812\n",
      "Epoch 40/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0656 - prec: 0.9791 - rec: 0.9794 - val_loss: 0.1548 - val_prec: 0.9402 - val_rec: 0.9854\n",
      "Epoch 41/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0667 - prec: 0.9793 - rec: 0.9792 - val_loss: 0.0958 - val_prec: 0.9839 - val_rec: 0.9592\n",
      "Epoch 42/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0640 - prec: 0.9804 - rec: 0.9804 - val_loss: 0.0841 - val_prec: 0.9729 - val_rec: 0.9739\n",
      "Epoch 43/50\n",
      "306/306 [==============================] - 39s 129ms/step - loss: 0.0642 - prec: 0.9797 - rec: 0.9799 - val_loss: 0.0868 - val_prec: 0.9800 - val_rec: 0.9718\n",
      "Epoch 44/50\n",
      "306/306 [==============================] - 40s 129ms/step - loss: 0.0599 - prec: 0.9811 - rec: 0.9814 - val_loss: 0.1038 - val_prec: 0.9571 - val_rec: 0.9801\n",
      "Epoch 45/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0615 - prec: 0.9808 - rec: 0.9814 - val_loss: 0.0946 - val_prec: 0.9659 - val_rec: 0.9760\n",
      "Epoch 46/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0604 - prec: 0.9813 - rec: 0.9816 - val_loss: 0.1189 - val_prec: 0.9611 - val_rec: 0.9812\n",
      "Epoch 47/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0591 - prec: 0.9816 - rec: 0.9816 - val_loss: 0.0811 - val_prec: 0.9800 - val_rec: 0.9707\n",
      "Epoch 48/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0593 - prec: 0.9821 - rec: 0.9826 - val_loss: 0.0926 - val_prec: 0.9708 - val_rec: 0.9728\n",
      "Epoch 49/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0574 - prec: 0.9825 - rec: 0.9834 - val_loss: 0.1972 - val_prec: 0.9482 - val_rec: 0.9749\n",
      "Epoch 50/50\n",
      "306/306 [==============================] - 39s 128ms/step - loss: 0.0550 - prec: 0.9831 - rec: 0.9834 - val_loss: 0.1158 - val_prec: 0.9582 - val_rec: 0.9822\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "log_dir = '../TB/res_baseline_256/'\n",
    "if os.path.exists(log_dir) == False:\n",
    "    os.makedirs(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "weights_path = '../../ml-data-training/deepfake_weights/'\n",
    "weights_save = CallbackForSavingModelWeights(weights_path)\n",
    "train_dataset = get_data(train, shape = (128, 128), batch_size=128)\n",
    "val_dataset = get_data(val, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)\n",
    "with strategy.scope():\n",
    "    model = create_model('ResNet50', (128, 128, 3))\n",
    "    model = compile_new_model(model)\n",
    "    model_hist = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch = len(train) // (128 * REPLICAS),\n",
    "        epochs = 50,\n",
    "        verbose = 1,\n",
    "        validation_data = val_dataset,\n",
    "        callbacks = [tensorboard_callback, weights_save]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('../../ml-data-training/deepfake_weights/37.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(train, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)\n",
    "val_dataset = get_data(val, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)\n",
    "test_dataset = get_data(test, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 79ms/step - loss: 0.1065 - prec: 0.9612 - rec: 0.9642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10647476464509964, 0.9612159132957458, 0.9642481803894043]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 13s 41ms/step - loss: 0.0603 - prec: 0.9773 - rec: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06027475744485855, 0.977334201335907, 0.9820473194122314]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 65ms/step - loss: 0.0831 - prec: 0.9660 - rec: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08309068530797958, 0.9660144448280334, 0.9801462888717651]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(train, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)\n",
    "train_imgs = train_dataset.map(lambda img, label: img)\n",
    "val_dataset = get_data(val, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)\n",
    "val_imgs = val_dataset.map(lambda img, label: img)\n",
    "test_dataset = get_data(test, shape = (128, 128), batch_size=128, shuffle=False, repeat=False)\n",
    "test_imgs = test_dataset.map(lambda img, label: img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 13s 40ms/step\n",
      "4/4 [==============================] - 1s 65ms/step\n",
      "4/4 [==============================] - 1s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(train_imgs, verbose = 1)\n",
    "val_preds = model.predict(val_imgs, verbose = 1)\n",
    "test_preds = model.predict(test_imgs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "for x in range(len(train)):\n",
    "    folder_name = train[x][0].split('/')[-2]\n",
    "    if folder_name not in dict_data:\n",
    "        dict_data[folder_name] = [x]\n",
    "    else:\n",
    "        dict_data[folder_name].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_preds = np.where(train_preds.flatten() < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([295]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(updated_preds[dict_data['ekkdjkirzq']], return_counts  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ekkdjkirzq\n",
      "dwediigjit\n",
      "esxrvsgpvb\n",
      "ensyyivobf\n",
      "cpjxareypw\n",
      "dgzklxjmix\n",
      "cnilkgvfei\n",
      "cferslmfwh\n",
      "ebkzwjgjhq\n",
      "dakqwktlbi\n",
      "dboxtiehng\n",
      "avywawptfc\n",
      "akzbnazxtz\n",
      "ebebgmtlcu\n",
      "ehfiekigla\n",
      "degpbqvcay\n",
      "byqzyxifza\n",
      "aybumesmpk\n",
      "eprybmbpba\n",
      "dkwjwbwgey\n",
      "asaxgevnnp\n",
      "avgiuextiz\n",
      "bzmdrafeex\n",
      "afoovlsmtx\n",
      "dofusvhnib\n",
      "egbbcxcuqy\n",
      "ehieahnhte\n",
      "dbzpcjntve\n",
      "epymyyiblu\n",
      "ciyoudyhly\n",
      "bqhtpqmmqp\n",
      "ddjggcasdw\n",
      "ddpvuimigj\n",
      "bwhlgysghg\n",
      "byfenovjnf\n",
      "dxbqjxrhin\n",
      "cettndmvzl\n",
      "axwovszumc\n",
      "aytzyidmgs\n",
      "bhbdugnurr\n",
      "eqvuznuwsa\n",
      "atkdltyyen\n",
      "axntxmycwd\n",
      "dnhvalzvrt\n",
      "diomeixhrg\n",
      "btunxncpjh\n",
      "bpxckdzddv\n",
      "ehccixxzoe\n",
      "ddqccgmtka\n",
      "avfitoutyn\n",
      "bggsurpgpr\n",
      "dptrzdvwpg\n",
      "bmjzrlszhi\n",
      "cqrskwiqng\n",
      "cwqlvzefpg\n",
      "aklqzsddfl\n",
      "asdpeebotb\n",
      "bbvgxeczei\n",
      "bhaaboftbc\n",
      "czkdanyadc\n",
      "ahbweevwpv\n",
      "eqjscdagiv\n",
      "dbhoxkblzx\n",
      "cwsbspfzck\n",
      "amaivqofda\n",
      "alvgwypubw\n",
      "bqnymlsayl\n",
      "ckjaibzfxa\n",
      "cepxysienc\n",
      "aufmsmnoye\n",
      "dlpoieqvfb\n",
      "dtbpmdqvao\n",
      "bvgwelbeof\n",
      "emgjphonqb\n",
      "dkdwxmtpuo\n",
      "byunigvnay\n",
      "bqeiblbxtl\n",
      "asvcrfdpnq\n",
      "dhoqofwoxa\n",
      "eejswgycjc\n",
      "elvvackpjh\n",
      "atyntldecu\n",
      "chzieimrwu\n",
      "emfbhytfhc\n",
      "cbbibzcoih\n",
      "bntlodcfeg\n",
      "dvumqqhoac\n",
      "dfbpceeaox\n",
      "arkroixhey\n",
      "eepezmygaq\n",
      "ddhfabwpuz\n",
      "axczxisdtb\n",
      "ekcrtigpab\n",
      "duycddgtrl\n",
      "amowujxmzc\n",
      "efdyrflcpg\n",
      "cyboodqqyr\n",
      "errocgcham\n",
      "ayqvfdhslr\n",
      "ckbdwedgmc\n",
      "eqnoqyfquo\n",
      "ekhacizpah\n",
      "esyhwdfnxs\n",
      "eczrseixwq\n",
      "cqhngvpgyi\n",
      "alaijyygdv\n",
      "dbnygxtwek\n",
      "cknyxaqouy\n",
      "dcuiiorugd\n",
      "aevrfsexku\n",
      "ahfazfbntc\n",
      "aipfdnwpoo\n",
      "ajwpjhrbcv\n",
      "andaxzscny\n",
      "ccmonzqfrz\n",
      "axwgcsyphv\n",
      "crezycjqyk\n",
      "avtycwsgyb\n",
      "dtocdfbwca\n",
      "btiysiskpf\n",
      "dulanfulol\n",
      "bjsmaqefoi\n",
      "dxuplhwvig\n",
      "beyebyhrph\n",
      "adhsbajydo\n",
      "esnntzzajv\n",
      "cizlkenljw\n",
      "ckkuyewywx\n",
      "coadfnerlk\n",
      "dgmevclvzy\n",
      "bwuwstvsbw\n",
      "caqbrkogkb\n",
      "dkhlttuvmx\n",
      "deyyistcrd\n",
      "eukvucdetx\n",
      "egghxjjmfg\n",
      "avssvvsdhz\n",
      "cppdvdejkc\n",
      "btjwbtsgln\n",
      "bbhtdfuqxq\n",
      "bseamdrpbj\n",
      "bqqpbzjgup\n",
      "etohcvnzbj\n",
      "aladcziidp\n",
      "bdbhekrrwo\n",
      "bejhvclboh\n",
      "crzfebnfgb\n",
      "ahdbuwqxit\n",
      "cdphtzqrvp\n",
      "dzieklokdr\n",
      "dhevettufk\n",
      "avmjormvsx\n",
      "adylbeequz\n",
      "augtsuxpzc\n",
      "ccfoszqabv\n",
      "dsndhujjjb\n",
      "byijojkdba\n",
      "dntkzzzcdh\n",
      "cdbsbdymzd\n",
      "aelfnikyqj\n",
      "bjkmjilrxp\n",
      "chtapglbcj\n",
      "eudeqjhdfd\n",
      "bctvsmddgq\n",
      "dsgpbgsrdm\n",
      "byofowlkki\n",
      "brhalypwoo\n",
      "blpchvmhxx\n",
      "ehdkmxgtxh\n",
      "eoewqcpbgt\n",
      "cffffbcywc\n",
      "dqzreruvje\n",
      "ecujsjhscd\n",
      "dozyddhild\n",
      "bpapbctoao\n",
      "bvzjkezkms\n",
      "arrhsnjqku\n",
      "dqppxmoqdl\n",
      "bguwlyazau\n",
      "dqnyszdong\n",
      "ehtdtkmmli\n",
      "ctzmavwror\n",
      "acxwigylke\n",
      "eckvhdusax\n",
      "cprhtltsjp\n",
      "dubiroskqn\n",
      "bwipwzzxxu\n",
      "cyxlcuyznd\n",
      "drtbksnpol\n",
      "apgjqzkoma\n",
      "eixwxvxbbn\n",
      "dbhrpizyeq\n",
      "dzyuwjkjui\n",
      "arlmiizoob\n",
      "dakiztgtnw\n",
      "abqwwspghj\n",
      "btxlttbpkj\n",
      "bdxuhamuqx\n",
      "bdnaqemxmr\n",
      "azsmewqghg\n",
      "deywhkarol\n",
      "czmqpxrqoh\n",
      "dhkwmjxwrn\n",
      "adohikbdaz\n",
      "dkuayagnmc\n",
      "dnexlwbcxq\n",
      "djvtbgwdcc\n",
      "ctpqeykqdp\n",
      "bghphrsfxf\n",
      "bgvhtpzknn\n",
      "asmpfjfzif\n",
      "dhcndnuwta\n",
      "bdgipnyobr\n",
      "btohlidmru\n",
      "cdyakrxkia\n",
      "crktehraph\n",
      "dhxctgyoqj\n",
      "dhcselezer\n",
      "elginszwtk\n",
      "alninxcyhg\n",
      "atxvxouljq\n",
      "cthdnahrkh\n",
      "bmioepcpsx\n",
      "bkmdzhfzfh\n",
      "bgmlwsoamc\n",
      "dafhtipaml\n",
      "aqpnvjhuzw\n",
      "bkwxhglwct\n",
      "ebchwmwayp\n",
      "ehevsxtecd\n",
      "aagfhgtpmv\n",
      "bgwmmujlmc\n",
      "bddjdhzfze\n",
      "blzydqdfem\n",
      "cttqtsjvgn\n",
      "cvaksbpssm\n",
      "akvmwkdyuv\n",
      "dkrvorliqc\n",
      "abofeumbvv\n",
      "cqfugiqupm\n",
      "bourlmzsio\n",
      "anpuvshzoo\n",
      "eahlqmfvtj\n",
      "dhjmzhrcav\n",
      "erlvuvjsjf\n",
      "byyqectxqa\n",
      "awnwkrqibf\n",
      "cbltdtxglo\n",
      "esckbnkkvb\n",
      "btmsngnqhv\n",
      "bzythlfnhq\n",
      "bydaidkpdp\n",
      "dlrsbscitn\n",
      "dxuliowugt\n",
      "eggbjzxnmg\n",
      "ecwaxgutkc\n",
      "brvqtabyxj\n",
      "bmbbkwmxqj\n",
      "cwrtyzndpx\n",
      "aelzhcnwgf\n",
      "agrmhtjdlk\n",
      "dnyvfblxpm\n",
      "agdkmztvby\n",
      "duzuusuajr\n",
      "cxfujlvsuw\n",
      "ecnihjlfyt\n",
      "edyncaijwx\n",
      "cobjrlugvp\n",
      "eebserckhh\n",
      "diqraixiov\n",
      "eajlrktemq\n",
      "atvmxvwyns\n",
      "eekozbeafq\n",
      "dqqtjcryjv\n",
      "bhsluedavd\n",
      "dbzcqmxzaj\n",
      "cdaxixbosp\n",
      "boovltmuwi\n",
      "bffwsjxghk\n",
      "benmsfzfaz\n",
      "bofqajtwve\n",
      "doanjploai\n",
      "acifjvzvpm\n",
      "beboztfcme\n",
      "aneclqfpbt\n",
      "dzqwgqewhu\n",
      "drsakwyvqv\n",
      "bmjmjmbglm\n",
      "awukslzjra\n",
      "ebeknhudxq\n",
      "akxoopqjqz\n",
      "bqdjzqhcft\n",
      "cxttmymlbn\n",
      "axoygtekut\n",
      "aknbdpmgua\n",
      "ahqqqilsxt\n",
      "acqfdwsrhi\n",
      "ebywfrmhtd\n",
      "btugrnoton\n",
      "etmcruaihe\n",
      "apatcsqejh\n",
      "altziddtxi\n",
      "atzdznmder\n",
      "emaalmsonj\n",
      "cwbacdwrzo\n",
      "chviwxsfhg\n",
      "esyrimvzsa\n",
      "aknmpoonls\n",
      "eiwopxzjfn\n",
      "dzvyfiarrq\n",
      "bmehkyanbj\n",
      "dbtbbhakdv\n",
      "bweezhfpzp\n",
      "aorjvbyxhw\n",
      "ajqslcypsw\n",
      "duvyaxbzvp\n",
      "apogckdfrz\n",
      "cmxcfkrjiv\n",
      "bgaogsjehq\n",
      "dzwkmcwkwl\n",
      "btjlfpzbdu\n",
      "bilnggbxgu\n",
      "bkvetcojbt\n",
      "ddepeddixj\n",
      "aettqgevhz\n",
      "agqphdxmwt\n",
      "cuzrgrbvil\n",
      "dptbnjnkdg\n",
      "cgvrgibpfo\n",
      "clrycekyst\n",
      "bbhpvrmbse\n",
      "diuzrpqjli\n",
      "cmbzllswnl\n",
      "bnbuonyoje\n",
      "djxdyjopjd\n",
      "erqgqacbqe\n",
      "djvutyvaio\n",
      "aslsvlvpth\n",
      "dqswpjoepo\n",
      "aybgughjxh\n",
      "cxrfacemmq\n",
      "ellavthztb\n",
      "aapnvogymq\n",
      "dkzvdrzcnr\n",
      "eeyhxisdfh\n",
      "bmhvktyiwp\n",
      "dsjbknkujw\n",
      "drgjzlxzxj\n",
      "clihsshdkq\n",
      "etdcqxabww\n",
      "ecuvtoltue\n",
      "aczrgyricp\n",
      "caifxvsozs\n",
      "eiriyukqqy\n",
      "brwrlczjvi\n",
      "esgftaficx\n",
      "cyclgfjdrv\n",
      "bulkxhhknf\n",
      "ceymbecxnj\n",
      "dcamvmuors\n",
      "acxnxvbsxk\n",
      "bchnbulevv\n",
      "dvakowbgbt\n",
      "diopzaywor\n",
      "avnqydkqjj\n",
      "etejaapnxh\n",
      "cfxkpiweqt\n",
      "cfyduhpbps\n",
      "cglxirfaey\n",
      "eebrkicpry\n",
      "czfunozvwp\n",
      "bndybcqhfr\n",
      "ehbnclaukr\n",
      "avibnnhwhp\n",
      "bxzakyopjf\n",
      "bsqgziaylx\n",
      "avvdgsennp\n",
      "efwfxwwlbw\n",
      "cksanfsjhc\n",
      "bsfmwclnqy\n",
      "curpwogllm\n",
      "bahdpoesir\n",
      "bhpwpydzpo\n",
      "eivxffliio\n",
      "covdcysmbi\n",
      "awhmfnnjih\n",
      "cycacemkmt\n",
      "bjjbwsqjir\n",
      "bqkdbcqjvb\n",
      "ejkqesyvam\n",
      "cwwandrkus\n",
      "abarnvbtwb\n",
      "dgxrqjdomn\n",
      "dsdoseflas\n",
      "bqtuuwzdtr\n",
      "bpwzipqtxf\n",
      "drcyabprvt\n",
      "bnjcdrfuov\n",
      "azpuxunqyo\n",
      "bopqhhalml\n"
     ]
    }
   ],
   "source": [
    "for key, val in dict_data.items():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "tensor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
